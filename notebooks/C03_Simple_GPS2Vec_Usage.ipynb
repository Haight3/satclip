{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## C03 - Use GPS2Vec embeddings\n",
        "\n",
        "Simple example of how to obtain pretrained CSP embeddings. Read the paper here:[https://arxiv.org/abs/2305.01118](https://arxiv.org/abs/2305.01118). Note that this notebook needs to be run with GPU enabled. To do this got to: \"Runtime -> Change runtime type\""
      ],
      "metadata": {
        "id": "ngz8zz9Gvbxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r sample_data .config # Empty current directory\n",
        "!git clone https://github.com/yifangyin/GPS2Vec.git . # Clone GPS2Vec repository"
      ],
      "metadata": {
        "id": "I4-8JQhl0ntG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utm"
      ],
      "metadata": {
        "id": "_y16t1ho04qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O models_tag.zip 'https://www.dropbox.com/s/j8b4h3ynkv42gj4/models_tag.zip?dl=1'\n",
        "!wget -O models_visual.zip 'https://www.dropbox.com/s/kcsadz2fl6ynymh/models_visual.zip?dl=1'"
      ],
      "metadata": {
        "id": "Op4IY-t-2QO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q models_tag.zip\n",
        "!unzip -q models_visual.zip"
      ],
      "metadata": {
        "id": "GXd2WAYt2fsb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gps2vec import *\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "e7yzSifX01l4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gps2vec(locations,basedir,model='visual'):\n",
        "    nrows = 20\n",
        "    ncols = 20\n",
        "    sigma = 20000\n",
        "    if model=='visual':\n",
        "      modeldir=basedir+\"/models_visual\"\n",
        "      flag = 0\n",
        "    elif model=='tag':\n",
        "      modeldir=basedir+\"/models_tag\"\n",
        "      flag = 1\n",
        "    else:\n",
        "      raise ValueError('Invalid model')\n",
        "    out = []\n",
        "    for location in locations:\n",
        "      geofea = georep(location,modeldir,nrows,ncols,sigma,flag)\n",
        "      out.append(np.asarray(geofea))\n",
        "    return np.asarray(out, dtype=object)"
      ],
      "metadata": {
        "id": "MYtxk8NCvr0M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.Tensor([[-74.0060, 40.7128], [-118.2437, 34.0522]])  # Represents a batch of 2 locations (lon/lat)\n",
        "\n",
        "emb = get_gps2vec(np.flip(c.numpy(),1),'',model='visual')"
      ],
      "metadata": {
        "id": "l7xHob8y1OSM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}